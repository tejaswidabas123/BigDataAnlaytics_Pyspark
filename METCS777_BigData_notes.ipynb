{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuUt1N/1+IALHOUYat3MuL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhardwajshivam/PySpark-Basics/blob/main/METCS777_BigData_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHMQyxT0NE2K",
        "outputId": "7b75efb4-ffb3-442d-fbde-67320af10d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=c4eb2c0de08d275af7c02adf319e16460e025f9bd0fa3845a38625d7034b54c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueT1Ko6oN1rk",
        "outputId": "93a7669f-8595-4f04-f68b-c18650f948e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "sc = SparkContext(\"local\")\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "ZoPdEVTUNMgG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "a9WvKpo4Nzu4",
        "outputId": "e83caf42-62ee-49f2-fd43-cf11239e986e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b4f31f9ab49e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split sentence into words\n",
        "lines = sc.parallelize([\n",
        "    \"Apache Spark is a unified analytics engine for large-scale data processing.\",\n",
        "    \"It provides high-level APIs in Java, Scala, Python and R\",\n",
        "    \"it also supports a rich set of higher-level tools including Spark SQL\",\n",
        "    \"MLlib for machine learning\",\n",
        "    \"GraphX for graph processing\",\n",
        "    \"Structured Streaming for incremental computation and stream processing\"\n",
        " ])\n",
        "\n",
        "words = lines.flatMap(lambda x: x.split(' '))\n",
        "print(lines.collect())\n",
        "print(words.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ444jVuN54A",
        "outputId": "9411fd51-1511-454a-bb24-2cb9908ff14d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apache Spark is a unified analytics engine for large-scale data processing.', 'It provides high-level APIs in Java, Scala, Python and R', 'it also supports a rich set of higher-level tools including Spark SQL', 'MLlib for machine learning', 'GraphX for graph processing', 'Structured Streaming for incremental computation and stream processing']\n",
            "['Apache', 'Spark', 'is', 'a', 'unified', 'analytics', 'engine', 'for', 'large-scale', 'data', 'processing.', 'It', 'provides', 'high-level', 'APIs', 'in', 'Java,', 'Scala,', 'Python', 'and', 'R', 'it', 'also', 'supports', 'a', 'rich', 'set', 'of', 'higher-level', 'tools', 'including', 'Spark', 'SQL', 'MLlib', 'for', 'machine', 'learning', 'GraphX', 'for', 'graph', 'processing', 'Structured', 'Streaming', 'for', 'incremental', 'computation', 'and', 'stream', 'processing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = words.map(lambda x: (x,1))\n",
        "print(rdd1.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6YMNME2Ov-k",
        "outputId": "4726f47d-a2ae-4edb-ad2c-36dee05a1024"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Apache', 1), ('Spark', 1), ('is', 1), ('a', 1), ('unified', 1), ('analytics', 1), ('engine', 1), ('for', 1), ('large-scale', 1), ('data', 1), ('processing.', 1), ('It', 1), ('provides', 1), ('high-level', 1), ('APIs', 1), ('in', 1), ('Java,', 1), ('Scala,', 1), ('Python', 1), ('and', 1), ('R', 1), ('it', 1), ('also', 1), ('supports', 1), ('a', 1), ('rich', 1), ('set', 1), ('of', 1), ('higher-level', 1), ('tools', 1), ('including', 1), ('Spark', 1), ('SQL', 1), ('MLlib', 1), ('for', 1), ('machine', 1), ('learning', 1), ('GraphX', 1), ('for', 1), ('graph', 1), ('processing', 1), ('Structured', 1), ('Streaming', 1), ('for', 1), ('incremental', 1), ('computation', 1), ('and', 1), ('stream', 1), ('processing', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2 = rdd1.reduceByKey(lambda x, y : x+y)\n",
        "rdd2.collect()\n",
        "#for the same key, add up the values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohyoYvmGO9Ds",
        "outputId": "87c0be75-c3d4-49cc-e9e5-222d31136c5e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Apache', 1),\n",
              " ('Spark', 2),\n",
              " ('is', 1),\n",
              " ('a', 2),\n",
              " ('unified', 1),\n",
              " ('analytics', 1),\n",
              " ('engine', 1),\n",
              " ('for', 4),\n",
              " ('large-scale', 1),\n",
              " ('data', 1),\n",
              " ('processing.', 1),\n",
              " ('It', 1),\n",
              " ('provides', 1),\n",
              " ('high-level', 1),\n",
              " ('APIs', 1),\n",
              " ('in', 1),\n",
              " ('Java,', 1),\n",
              " ('Scala,', 1),\n",
              " ('Python', 1),\n",
              " ('and', 2),\n",
              " ('R', 1),\n",
              " ('it', 1),\n",
              " ('also', 1),\n",
              " ('supports', 1),\n",
              " ('rich', 1),\n",
              " ('set', 1),\n",
              " ('of', 1),\n",
              " ('higher-level', 1),\n",
              " ('tools', 1),\n",
              " ('including', 1),\n",
              " ('SQL', 1),\n",
              " ('MLlib', 1),\n",
              " ('machine', 1),\n",
              " ('learning', 1),\n",
              " ('GraphX', 1),\n",
              " ('graph', 1),\n",
              " ('processing', 2),\n",
              " ('Structured', 1),\n",
              " ('Streaming', 1),\n",
              " ('incremental', 1),\n",
              " ('computation', 1),\n",
              " ('stream', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top = rdd2.top(10, lambda x:x[1])\n",
        "#this returns the top 10 values wrt the values in (key,val) pair in rdd2\n",
        "print(top)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OobPhPDdPPTU",
        "outputId": "37388998-26ff-461b-bd5e-df97e87102b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('for', 4), ('Spark', 2), ('a', 2), ('and', 2), ('processing', 2), ('Apache', 1), ('is', 1), ('unified', 1), ('analytics', 1), ('engine', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#returns alphabetically (in the order z to a) the top 50 tuples\n",
        "print(rdd2.top(50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLVApB6WQBhK",
        "outputId": "78ac4412-5d41-4b62-f7a0-b1594f7a34fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('unified', 1), ('tools', 1), ('supports', 1), ('stream', 1), ('set', 1), ('rich', 1), ('provides', 1), ('processing.', 1), ('processing', 2), ('of', 1), ('machine', 1), ('learning', 1), ('large-scale', 1), ('it', 1), ('is', 1), ('incremental', 1), ('including', 1), ('in', 1), ('higher-level', 1), ('high-level', 1), ('graph', 1), ('for', 4), ('engine', 1), ('data', 1), ('computation', 1), ('and', 2), ('analytics', 1), ('also', 1), ('a', 2), ('Structured', 1), ('Streaming', 1), ('Spark', 2), ('Scala,', 1), ('SQL', 1), ('R', 1), ('Python', 1), ('MLlib', 1), ('Java,', 1), ('It', 1), ('GraphX', 1), ('Apache', 1), ('APIs', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimised version\n",
        "\n",
        "top_words = lines.flatMap(lambda x: x.split(' '))\\\n",
        "              .map(lambda x: x.lower())\\\n",
        "              .map(lambda x: x.replace(\".\",\"\").replace(\",\",\"\"))\\\n",
        "              .map(lambda x: (x,1))\\\n",
        "              .reduceByKey(lambda x, y: x+y)\\\n",
        "              .top(10, lambda x: x[1])"
      ],
      "metadata": {
        "id": "YIZeqeTMQGCS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5OKMN3PreKX",
        "outputId": "44d42236-f42f-438f-876e-99fabf55da87"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('for', 4), ('processing', 3), ('spark', 2), ('a', 2), ('it', 2), ('and', 2), ('apache', 1), ('is', 1), ('unified', 1), ('analytics', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RDD Basics"
      ],
      "metadata": {
        "id": "hT1CvmKisNQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1,2,3])"
      ],
      "metadata": {
        "id": "LKpnqo-krjYv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = rdd.collect()\n",
        "print(rdd)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWIyM7f7saXo",
        "outputId": "1f0bcc36-bc93-4142-ee37-98f2813f5a4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ParallelCollectionRDD[15] at readRDDFromFile at PythonRDD.scala:289\n",
            "[1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#take(num)\n",
        "\n",
        "x = sc.parallelize([1,3,1,2,3])\n",
        "y = x.take(num = 3) #takes the first 3\n",
        "print(\"x=\", x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoaQHmQKsm72",
        "outputId": "46864116-d789-4be6-a648-f2e7cd8ab5e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 1, 2, 3]\n",
            "[1, 3, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#takeOrdered\n",
        "x = sc.parallelize([1,3,1,2,3])\n",
        "y = x.takeOrdered(num = 3) #ascending\n",
        "print(\"x=\", x.collect())\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0ZfgR2ys524",
        "outputId": "d88bb526-4c73-489b-dbf1-b8ca05a7c4c6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 1, 2, 3]\n",
            "[1, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first() returns the first element in RDD\n",
        "\n",
        "x = sc.parallelize([1,3,1,2,3])\n",
        "y = x.first()\n",
        "print(\"x=\", x.collect())\n",
        "(\"the first element is\", y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lvIbcLEtQje",
        "outputId": "bcbb64ff-a731-4975-c6cd-07e1629f233b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 1, 2, 3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the first element is', 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using top() to print the biggest 3 and smallest 3 elements\n",
        "\n",
        "x = sc.parallelize([1,3,1,2,3])\n",
        "y = x.top(num = 3)\n",
        "print(\"x=\", x.collect())\n",
        "print(\"Biggest elements\", y)\n",
        "\n",
        "\n",
        "y = x.top(num =3, key = lambda x: -x)\n",
        "print(\"Smallest elements\", y)\n",
        "\n",
        "#if n > len(rdd), it returns the complete rdd\n",
        "\n",
        "y = x.top(num = 10)\n",
        "print(\"All elemnts\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SBUiek6v87t",
        "outputId": "d92d37bd-3f6e-44f9-b392-ce7da7f1fa54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 1, 2, 3]\n",
            "Biggest elements [3, 3, 2]\n",
            "Smallest elements [1, 1, 2]\n",
            "All elemnts [3, 3, 2, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#collectAsMap method returns a dictionary with key-value pairs in the RDD\n",
        "\n",
        "x = sc.parallelize([('C',3),('A',1),('B',2), ('D', 4), ('E', 5)])\n",
        "y = x.collectAsMap()\n",
        "print(\"x=\", x.collect())\n",
        "print(\"The dictionary of {key:vlaue} pairs:\",y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XED5RRzxEdi",
        "outputId": "8dceafcc-7300-4607-bca6-10284c536fcb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('C', 3), ('A', 1), ('B', 2), ('D', 4), ('E', 5)]\n",
            "The dictionary of {key:vlaue} pairs: {'C': 3, 'A': 1, 'B': 2, 'D': 4, 'E': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If there are duplicate keys, the value of the last key will be retained.\n",
        "x = sc.parallelize([('C',3),('A',1),('B',2), ('A', 4), ('B', 5)])\n",
        "y = x.collectAsMap()\n",
        "print(\"x=\",x.collect())\n",
        "print(\"Result if there are duplicates:\",y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IajWc1FyPgx",
        "outputId": "9a43436b-fdce-492f-ecb6-803660676d12"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('C', 3), ('A', 1), ('B', 2), ('A', 4), ('B', 5)]\n",
            "Result if there are duplicates: {'C': 3, 'A': 4, 'B': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Map\n",
        "\n",
        "x = sc.parallelize([\"b\", \"a\", \"c\"])\n",
        "y = x.map(lambda x: (x, 1))\n",
        "print(\"x=\",x.collect())  # collect copies RDD elements to a list on the driver\n",
        "print(y.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ravr1IYryYAL",
        "outputId": "0e7df141-3a66-41bf-d367-e0c1cf759963"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= ['b', 'a', 'c']\n",
            "[('b', 1), ('a', 1), ('c', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sc.parallelize([1,2,3,4,5])\n",
        "y = x.map(lambda x: x**2)\n",
        "print(\"x=\", x.collect())\n",
        "print(\"y=\", y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh9Ll2bCy0zJ",
        "outputId": "f2302349-e461-4a96-d8d4-3b9bd71a364c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 2, 3, 4, 5]\n",
            "y= [1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sc.parallelize([1,2,3,4,5])\n",
        "y = x.map(lambda x: (x,x**2))\n",
        "print(\"x=\", x.collect())\n",
        "print(\"y=\", y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcSNf9_mzG-2",
        "outputId": "b481f159-e123-4ccb-fcf0-7cf0420ddc17"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 2, 3, 4, 5]\n",
            "y= [(1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#flatMap\n",
        "\n",
        "x = sc.parallelize([(1,2,3),(2,3,4),(3,4,5)])\n",
        "y = x.map(lambda x: x)\n",
        "print(\"x=\", x.collect())\n",
        "print(\"Map result\", y.collect())\n",
        "\n",
        "\n",
        "y = x.flatMap(lambda x: x)\n",
        "print(\"x=\", x.collect())\n",
        "print(\"flatMap result\", y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myd7CamLzTis",
        "outputId": "bae73cca-1faf-431b-b361-f024e25de274"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [(1, 2, 3), (2, 3, 4), (3, 4, 5)]\n",
            "Map result [(1, 2, 3), (2, 3, 4), (3, 4, 5)]\n",
            "x= [(1, 2, 3), (2, 3, 4), (3, 4, 5)]\n",
            "flatMap result [1, 2, 3, 2, 3, 4, 3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sc.parallelize([1,2,3])\n",
        "y = x.flatMap(lambda x: (x, x**2, 100*x))\n",
        "print(\"x=\", x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNYP3j1S2taY",
        "outputId": "09b11af2-397b-4c21-a5b7-5984cb2957e5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 2, 3]\n",
            "[1, 1, 100, 2, 4, 200, 3, 9, 300]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vs Map\n",
        "x = sc.parallelize([1,2,3])\n",
        "y = x.map(lambda x: (x, 100*x, x**2))\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6ZiE_GX5kdt",
        "outputId": "8445e907-f59c-41e4-e7ba-dbe2cc8259a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 2, 3]\n",
            "[(1, 100, 1), (2, 200, 4), (3, 300, 9)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mapValues() applies a function f to each value in a key-value pair RDD, while retaining the original keys\n",
        "\n",
        "x = sc.parallelize([('A',(1,2,3)),('B',(4,5))])\n",
        "y = x.mapValues(lambda x: [i**2 for i in x]) #function being applied to entire value\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROOGsGeS5zQr",
        "outputId": "53b07ed2-82ba-4394-dee3-22ad6e34659b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('A', (1, 2, 3)), ('B', (4, 5))]\n",
            "[('A', [1, 4, 9]), ('B', [16, 25])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sc.parallelize([('A',(1,2,3)),('B',(4,5))])\n",
        "y = x.map(lambda x: (x[0], [i**2 for i in x[1]]))\n",
        "print(\"Using map()\")\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUYBnmNa6-sm",
        "outputId": "2032dd9d-fd88-497a-9ee0-2b00fb22a19a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using map()\n",
            "x= [('A', (1, 2, 3)), ('B', (4, 5))]\n",
            "[('A', [1, 4, 9]), ('B', [16, 25])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filter() method returns a new dataset formed by selecting the elements using the filtering condition\n",
        "\n",
        "x = sc.parallelize([1,2,3])\n",
        "y = x.filter(lambda x: x%2 == 1) #filter the odd elements\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ucwEBXW7Vyr",
        "outputId": "12d00394-9111-4a94-9e6e-ec52ef8c3990"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 2, 3]\n",
            "[1, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#distinct methods\n",
        "x = sc.parallelize(['A','A','B'])\n",
        "y = x.distinct()\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abA-ABEo7yie",
        "outputId": "31961425-6c40-48e9-aa97-bf30944b9e49"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= ['A', 'A', 'B']\n",
            "['A', 'B']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#keys() method returns a new rdd that contains only the keys of each tuple in the i/p rdd\n",
        "\n",
        "x = sc.parallelize([('C',3),('A',1),('B',2)])\n",
        "y = x.keys()\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on-gNXtZ9W7c",
        "outputId": "780961c0-a4f6-4fc8-e883-05f6aeadca65"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('C', 3), ('A', 1), ('B', 2)]\n",
            "['C', 'A', 'B']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#values() method returns a new RDD that contains only the values of each tuple\n",
        "x = sc.parallelize([('C',3),('A',1),('B',2)])\n",
        "y = x.values()\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFCM102i-ie6",
        "outputId": "4a1b3e1a-df08-4488-a4d3-b12137f62356"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('C', 3), ('A', 1), ('B', 2)]\n",
            "[3, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Partitions\n",
        "\n",
        "Partitions in Spark refer to the fundamental units of parallelism in distributed processing. When you work with large datasets in Spark, they are divided into smaller, more manageable chunks called partitions. Each partition contains a subset of the data and can be processed independently on different executor nodes in a cluster.\n",
        "\n",
        "Here are some key points about partitions in Spark:\n",
        "\n",
        "Parallel Processing: Spark performs computations in parallel by dividing the data into partitions. Each partition is processed independently by a task running on a separate executor, enabling parallelism and distributed computing.\n",
        "Data Distribution: Partitions help distribute the data across the nodes in a cluster. By dividing the data into smaller partitions, Spark can achieve load balancing and utilize the available resources efficiently.\n",
        "Partitioning Schemes: Spark provides various partitioning schemes, such as hash partitioning and range partitioning, to determine how the data is divided among partitions. The choice of partitioning scheme can impact data distribution and performance.\n",
        "Transformation and Actions: Transformations in Spark, such as map() or filter(), are applied on a per-partition basis. Actions like reduce() or collect() operate on the data across all partitions, leveraging parallelism.\n",
        "Control and Optimization: Partitions provide fine-grained control over data processing. Developers can control the number of partitions, repartition data, or perform custom partitioning to optimize performance and resource usage.\n",
        "Data Locality: Spark tries to achieve data locality, where partitions are processed on the same nodes where the data resides or is cached. This reduces data transfer across the network and improves performance.\n",
        "Shuffling: Certain operations, like groupBy() or join(), may require data to be shuffled across partitions. Shuffling involves redistributing data based on specific keys or criteria, which can incur additional overhead.\n",
        "Partition Size: The optimal partition size depends on factors like the available resources, data characteristics, and the specific workload. Choosing an appropriate partition size helps balance data distribution, minimize data skew, and avoid memory or performance issues."
      ],
      "metadata": {
        "id": "0LIJVpij_l4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#getNumPartitions method returns the number of partitions\n",
        "\n",
        "# getNumPartitions\n",
        "x = sc.parallelize([1,2,3,4,5,6,7,8,9,10,11,12,13,14], 5)\n",
        "y = x.getNumPartitions()\n",
        "print(x.glom().collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfudZpia_dN7",
        "outputId": "594f1b75-f5ff-4dda-df17-f81239b13ae8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2], [3, 4], [5, 6, 7, 8], [9, 10], [11, 12, 13, 14]]\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#repartition() returns a new rdd that has exactly numPartitions\n",
        "\n",
        "x = sc.parallelize([1,2,3,4,5],2)\n",
        "y = x.repartition(numPartitions=3)\n",
        "print(x.glom().collect())\n",
        "print(y.glom().collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk9SnDTeHfaw",
        "outputId": "0c6c9185-756d-424e-b0da-e9a8945e5c11"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2], [3, 4, 5]]\n",
            "[[1, 2], [3, 4, 5], []]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#coalesce() method returns a new rdd that is reduced into n partitions\n",
        "\n",
        "x = sc.parallelize([1,2,3,4,5,6,7,8,9,10,11,12,13,14], 4)\n",
        "y = x.coalesce(numPartitions=2)\n",
        "print(x.glom().collect())\n",
        "print(y.glom().collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDlXfvwBIcF4",
        "outputId": "b7f5438e-268e-4ba7-a41f-b9f08c464366"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12, 13, 14]]\n",
            "[[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12, 13, 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#glom() method returns a new RDD created by coalescing all elements within each partition into a list.\n",
        "\n",
        "x = sc.parallelize(['C','B','A'], 2)\n",
        "y = x.glom()\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTOBuP-aIuHM",
        "outputId": "f4e9bb03-7c8f-463e-9e12-34ce4093260e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= ['C', 'B', 'A']\n",
            "[['C'], ['B', 'A']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sampling\n"
      ],
      "metadata": {
        "id": "tEO8Ou7iJ1m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#takeSample() method returns a fixed-size sampled subset of the RDD. This operation requires the numpy library.\n",
        "\n",
        "x = sc.parallelize(range(7))\n",
        "ylist = [x.takeSample(withReplacement=False, num=3) for i in range(5)]  # call 'sample' 5 times\n",
        "print('x = ' + str(x.collect()))\n",
        "for cnt,y in zip(range(len(ylist)), ylist):\n",
        "    print('sample:' + str(cnt) + ' y = ' +  str(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNrjctMEJiko",
        "outputId": "84c7a418-0f10-475b-ad2b-0b5e1991afd0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = [0, 1, 2, 3, 4, 5, 6]\n",
            "sample:0 y = [6, 4, 0]\n",
            "sample:1 y = [5, 1, 6]\n",
            "sample:2 y = [0, 6, 5]\n",
            "sample:3 y = [5, 1, 0]\n",
            "sample:4 y = [6, 5, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#union() method returns a new RDD that represents the union of the elements in the source RDD and another RDD.\n",
        "\n",
        "x = sc.parallelize(['A','A','B'])\n",
        "y = sc.parallelize(['D','C','A'])\n",
        "z = x.union(y)\n",
        "print(\"x=\",x.collect())\n",
        "print(\"y=\",y.collect())\n",
        "print(z.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvS6uF-NKJp4",
        "outputId": "8af71b45-9921-4095-8aab-82c069d918d6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= ['A', 'A', 'B']\n",
            "y= ['D', 'C', 'A']\n",
            "['A', 'A', 'B', 'D', 'C', 'A']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#intersection() method returns a new RDD that represents the intersection of the elements in the source RDD and another RDD. The resulting RDD contains only the distinct elements that are common to both RDDs.\n",
        "\n",
        "x = sc.parallelize(['A','A','B'])\n",
        "y = sc.parallelize(['A','C','D'])\n",
        "z = x.intersection(y)\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())\n",
        "print(z.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KcSbhTDLZec",
        "outputId": "8a0d2672-f24e-4b36-e675-5c4617c7914e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= ['A', 'A', 'B']\n",
            "['A', 'C', 'D']\n",
            "['A']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reduce() method reduces the elements of the RDD using the specified commutative and associative binary operator f. It performs the reduction operation locally within each partition of the RDD.\n",
        "\n",
        "# reduce\n",
        "x = sc.parallelize([1,2,3])\n",
        "y = x.reduce(lambda x, y: x + y)  # computes a cumulative sum\n",
        "print(\"x=\",x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwlT0vFnLhkb",
        "outputId": "5ff28cb9-5d48-4b6a-e718-168a2d393f85"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 2, 3]\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fold() method aggregates the elements of each partition in an RDD and then combines the results of all partitions using a given associative function and a neutral \"zero value\". The op function is used to perform the aggregation and must adhere to certain requirements.\n",
        "\n",
        "# fold\n",
        "x = sc.parallelize([1,2,3])\n",
        "neutral_zero_value = 0  # 0 for sum, 1 for multiplication\n",
        "y = x.fold(neutral_zero_value,lambda obj, accumulated: accumulated + obj) # computes cumulative sum\n",
        "print(\"x=\",x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmJBpQYYLxvJ",
        "outputId": "a076818d-fa1b-442a-8800-6d6f3804b992"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 2, 3]\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#aggregate() method aggregates the elements of each partition in an RDD and then combines the results\n",
        "#of all partitions using given combine functions and a neutral \"zero value\".\n",
        "#This operation allows for different result types for the sequential and combined operations.\n",
        "\n",
        "'''\n",
        "Parameters:\n",
        "\n",
        "zeroValue: The initial or neutral value for the aggregation operation.\n",
        "seqOp: The sequential operation function used for aggregating the elements within each partition.\n",
        "combOp: The combined operation function used for merging the results of different partitions.\n",
        "'''\n",
        "\n",
        "x = sc.parallelize([2,3,4])\n",
        "neutral_zero_value = (0,1) #0 for sum and 1 for multiplication\n",
        "seqOp = (lambda aggregated, el: (aggregated[0] + el, aggregated[1] + el))\n",
        "combOp = (lambda aggregated1, aggregated2: (aggregated1[0] + aggregated2[0], aggregated1[1] * aggregated2[1]))\n",
        "y = x.aggregate(neutral_zero_value, seqOp, combOp)\n",
        "\n",
        "print(\"x=\", x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "id": "0ARlNI_aMEG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751ea03c-b5c6-4cc4-f99c-3658a22e3acc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [2, 3, 4]\n",
            "(9, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reduceByKey() method merges the values for each key in an RDD using an associative reduce function.\n",
        "x = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\n",
        "y = x.reduceByKey(lambda agg, obj: agg + obj)\n",
        "print(\"x = \", x.collect())\n",
        "print(\"y = \", y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEv3ADSPKKEN",
        "outputId": "19298cc3-903c-48b4-8484-c8f7e8e2db43"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  [('B', 1), ('B', 2), ('A', 3), ('A', 4), ('A', 5)]\n",
            "y =  [('B', 3), ('A', 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#foldByKey\n",
        "'''\n",
        "foldByKey(zeroValue, func, numPartitions=None)\n",
        "\n",
        "The foldByKey() method merges the values for each key in an RDD using an associative function\n",
        " func and a neutral zeroValue. The zeroValue can be added to the result an arbitrary number\n",
        " of times and should not affect the final outcome.\n",
        "'''\n",
        "\n",
        "x = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\n",
        "zeroValue = 1 # one is 'zero value' for multiplication\n",
        "y = x.foldByKey(zeroValue,lambda agg,x: agg*x )  # computes cumulative product within each key\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC90I3f7Lo14",
        "outputId": "e86bae8c-d09c-442c-ef58-29ee73e473ab"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('B', 1), ('B', 2), ('A', 3), ('A', 4), ('A', 5)]\n",
            "[('B', 2), ('A', 60)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\n",
        "zeroValue = 0 # one is 'zero value' for add\n",
        "y = x.foldByKey(zeroValue,lambda agg,x: agg+x )  # computes cumulative product within each key\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL3fyhffNXak",
        "outputId": "0b27f67c-7cd8-4639-9fb2-b6c63a43548e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('B', 1), ('B', 2), ('A', 3), ('A', 4), ('A', 5)]\n",
            "[('B', 3), ('A', 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#aggregateByKey()\n",
        "\n",
        "'''\n",
        "method aggregates the values of each key in an RDD using given combine functions and a neutral \"zero value\".\n",
        "This function allows for a different result type U than the type of the values in the RDD V.\n",
        "It requires two operations: one for merging a V into a U within a partition and another for merging two U\n",
        "values between partitions. These operations can modify and return their first argument to avoid memory allocation.\n",
        "\n",
        "Parameters:\n",
        "\n",
        "zeroValue: The neutral value or zero value for the aggregation operation.\n",
        "seqFunc: The function used to merge a value V into an intermediate result U within each partition.\n",
        "combFunc: The function used to merge two intermediate results U between partitions.\n",
        "numPartitions (optional): The number of partitions to use for the resulting RDD. If not specified, the default partitioning scheme will be used.\n",
        "'''\n",
        "\n",
        "x = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\n",
        "zeroValue = [] # empty list is 'zero value' for append operation\n",
        "mergeVal = (lambda aggregated, el: aggregated + [(el,el**2)])\n",
        "mergeComb = (lambda agg1,agg2: agg1 + agg2 )\n",
        "y = x.aggregateByKey(zeroValue,mergeVal,mergeComb)\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yahX7Gw8Nc6P",
        "outputId": "f35b40d0-f245-4470-9f22-5ab9fbf860f2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('B', 1), ('B', 2), ('A', 3), ('A', 4), ('A', 5)]\n",
            "[('B', [(1, 1), (2, 4)]), ('A', [(3, 9), (4, 16), (5, 25)])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#groupByKey\n",
        "\n",
        "x = sc.parallelize([('B',5),('B',4),('A',3),('A',2),('A',1)])\n",
        "y = x.groupByKey() #this will group all A and B together. A: all info of A, B: all info of B\n",
        "print(\"x=\",x.collect())\n",
        "print([(j[0],[i for i in j[1]]) for j in y.collect()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OwgLqInOJXU",
        "outputId": "e28de4b7-adb5-46c6-a743-3164ec1a283d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('B', 5), ('B', 4), ('A', 3), ('A', 2), ('A', 1)]\n",
            "[('B', [5, 4]), ('A', [3, 2, 1])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#countByKey\n",
        "\n",
        "'''\n",
        "The countByKey() method counts the number of elements for each key in an\n",
        "RDD and returns the result as a dictionary to the driver program.\n",
        "'''\n",
        "\n",
        "x = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\n",
        "y = x.countByKey()\n",
        "print(\"x=\",x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln_MiaAXPCaU",
        "outputId": "d66f02b8-7f2f-457a-e3e6-c67b80a9c900"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('B', 1), ('B', 2), ('A', 3), ('A', 4), ('A', 5)]\n",
            "defaultdict(<class 'int'>, {'B': 2, 'A': 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#countByValue() -> given a list, count the occurence\n",
        "'''\n",
        "method counts the occurrences of each unique value in an RDD and returns the\n",
        "result as a dictionary where the keys are the unique values and the values are the counts.\n",
        "'''\n",
        "\n",
        "x = sc.parallelize([1,3,1,2,3])\n",
        "y = x.countByValue()\n",
        "print(\"x=\",x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbWN2Jd8PfX0",
        "outputId": "860c8121-4118-412b-c0c8-0317ab6dbf13"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 1, 2, 3]\n",
            "defaultdict(<class 'int'>, {1: 2, 3: 2, 2: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics"
      ],
      "metadata": {
        "id": "GYt7T6dvP6xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#count() method returns the number of elements in an RDD.\n",
        "\n",
        "x = sc.parallelize([1,3,2])\n",
        "y = x.count()\n",
        "print(\"x=\",x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnA_3kYsPxt8",
        "outputId": "368ed6fc-47c8-4533-dda7-224e259ab1cf"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 2]\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max\n",
        "\n",
        "x = sc.parallelize([1,9,4,2,11])\n",
        "y = x.max()\n",
        "z = x.max(key=str) #this gives second max\n",
        "print(\"x=\",x.collect())\n",
        "print(y)\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4XOJ6QxQCgb",
        "outputId": "5e4a97f3-d6d4-472a-8707-dd2617c2f3b0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 9, 4, 2, 11]\n",
            "11\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#min\n",
        "\n",
        "x = sc.parallelize([1,3,2])\n",
        "y = x.min()\n",
        "print(\"x=\",x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_E2cHwYQPyl",
        "outputId": "94934335-7892-4705-f160-0dd1cb673abd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 2]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sum\n",
        "\n",
        "x = sc.parallelize([1,3,2])\n",
        "y = x.sum()\n",
        "print(\"x=\",x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJQSRH6sRDP2",
        "outputId": "df716156-9b0f-463f-b74e-a41e54b00414"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 2]\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mean\n",
        "\n",
        "x = sc.parallelize([1,3,2])\n",
        "y = x.mean()\n",
        "print(\"x=\",x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_rasPx-RIos",
        "outputId": "07803e17-4aa9-4b7a-b6fd-51f7cd867ea8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 2]\n",
            "2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#variance ''variance = sd**2\n",
        "\n",
        "x = sc.parallelize([1,3,2])\n",
        "y = x.variance()  # divides by N\n",
        "print(\"x=\",x.collect())\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-iGCoCPRMEt",
        "outputId": "7139346f-e9d0-4ca2-ec00-7b601fc0c470"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 2]\n",
            "0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stdev\n",
        "\n",
        "x = sc.parallelize([1,3,2])\n",
        "y = x.stdev()  # divides by N\n",
        "print(\"x=\",x.collect())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbB6gssnRREq",
        "outputId": "c067347f-f326-422d-a23b-63f1c2f4918d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 3, 2]\n",
            "0.816496580927726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Join and combine RDDs"
      ],
      "metadata": {
        "id": "bnRBtNtdRnco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#join\n",
        "\n",
        "x = sc.parallelize([('C',4),('B',3),('A',2),('A',1)])\n",
        "y = sc.parallelize([('A',8),('B',7),('A',6),('D',5)])\n",
        "z = x.join(y)\n",
        "print(\"x=\",x.collect())\n",
        "print(\"y=\",y.collect())\n",
        "print(z.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqgz4JcDRl5s",
        "outputId": "bce230aa-cf18-4222-b15a-99756d76b9f8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('C', 4), ('B', 3), ('A', 2), ('A', 1)]\n",
            "y= [('A', 8), ('B', 7), ('A', 6), ('D', 5)]\n",
            "[('B', (3, 7)), ('A', (2, 8)), ('A', (2, 6)), ('A', (1, 8)), ('A', (1, 6))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#leftOuterJoin of x and y will give all elements of x and x intersection y\n",
        "\n",
        "x = sc.parallelize([('C',4),('B',3),('A',2),('A',1)])\n",
        "y = sc.parallelize([('A',8),('B',7),('A',6),('D',5)]) #as we can see, there is no D in x so leftOuterJoin of x on y will not have D\n",
        "z = x.leftOuterJoin(y)\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())\n",
        "print(z.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0P3970KS87p",
        "outputId": "9bbd38cc-cc19-4d86-b209-28b17d145cf2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('C', 4), ('B', 3), ('A', 2), ('A', 1)]\n",
            "[('A', 8), ('B', 7), ('A', 6), ('D', 5)]\n",
            "[('C', (4, None)), ('B', (3, 7)), ('A', (2, 8)), ('A', (2, 6)), ('A', (1, 8)), ('A', (1, 6))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rightOuterJoin of x on y will give all elements of y and x intersection y\n",
        "\n",
        "x = sc.parallelize([('C',4),('B',3),('A',2),('A',1)]) #this will not have\n",
        "y = sc.parallelize([('A',8),('B',7),('A',6),('D',5)])\n",
        "z = x.rightOuterJoin(y)\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())\n",
        "print(z.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wpxnXUBTLwT",
        "outputId": "53f2b70d-fbc3-4ad3-c536-7581ec30a01f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('C', 4), ('B', 3), ('A', 2), ('A', 1)]\n",
            "[('A', 8), ('B', 7), ('A', 6), ('D', 5)]\n",
            "[('B', (3, 7)), ('A', (2, 8)), ('A', (2, 6)), ('A', (1, 8)), ('A', (1, 6)), ('D', (None, 5))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cartesian -> gives all combinations\n",
        "\n",
        "x = sc.parallelize(['A','B'])\n",
        "y = sc.parallelize(['C','D'])\n",
        "z = x.cartesian(y)\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())\n",
        "print(z.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmLYwZ3FT64b",
        "outputId": "67bde022-ca0d-4133-c5aa-05214affe9bf"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= ['A', 'B']\n",
            "['C', 'D']\n",
            "[('A', 'C'), ('A', 'D'), ('B', 'C'), ('B', 'D')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subtract\n",
        "\n",
        "x = sc.parallelize([('C',4),('B',3),('A',2),('A',1)])\n",
        "y = sc.parallelize([('C',8),('A',2),('D',2)])\n",
        "z = x.subtract(y) #('A',2) will be removed from x\n",
        "print(\"x=\",x.collect())\n",
        "print(\"x=\",y.collect())\n",
        "print(z.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFHHs01lWI_l",
        "outputId": "6c8b3301-47a5-4602-bc8d-6ffa3952b154"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('C', 4), ('B', 3), ('A', 2), ('A', 1)]\n",
            "x= [('C', 8), ('A', 2), ('D', 2)]\n",
            "[('C', 4), ('B', 3), ('A', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#zip() -> zips two rdd together\n",
        "\n",
        "x = sc.parallelize(['B','A','A'])\n",
        "y = x.map(lambda x: ord(x))  # zip expects x and y to have same #partitions and #elements/partition\n",
        "z = x.zip(y)\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())\n",
        "print(z.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCOkndmmWVs7",
        "outputId": "59f1c8d5-59fa-49bb-c7ca-f2fe46aed631"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= ['B', 'A', 'A']\n",
            "[66, 65, 65]\n",
            "[('B', 66), ('A', 65), ('A', 65)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#zipWithIndex\n",
        "\n",
        "x = sc.parallelize(['B','A','A'],2)\n",
        "y = x.zipWithIndex()\n",
        "print(x.glom().collect())\n",
        "print(y.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ljt2bgyWuEx",
        "outputId": "f1e4d0b8-7b82-4f14-b02a-006409996289"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['B'], ['A', 'A']]\n",
            "[('B', 0), ('A', 1), ('A', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#other functions"
      ],
      "metadata": {
        "id": "E-grs-7SXVtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sortByKey\n",
        "x = sc.parallelize([('B',1),('A',2),('C',3)])\n",
        "y = x.sortByKey()\n",
        "print(\"x=\",x.collect())\n",
        "print(y.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKhYrwgqXRB_",
        "outputId": "1fa07f96-f4a9-4f04-bf2d-25027d80ef7b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [('B', 1), ('A', 2), ('C', 3)]\n",
            "[('A', 2), ('B', 1), ('C', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# foreach\n",
        "from __future__ import print_function\n",
        "x = sc.parallelize([1,2,3])\n",
        "def f(el):\n",
        "    '''side effect: append the current RDD elements to a file'''\n",
        "    f1=open(\"./foreachExample.txt\", 'a+')\n",
        "    print(el,file=f1)\n",
        "\n",
        "open('./foreachExample.txt', 'w').close()  # first clear the file contents\n",
        "\n",
        "y = x.foreach(f) # writes into foreachExample.txt\n",
        "\n",
        "print(\"x=\",x.collect())\n",
        "print(y) # foreach returns 'None'\n",
        "# print the contents of foreachExample.txt\n",
        "with open(\"./foreachExample.txt\", \"r\") as foreachExample:\n",
        "    print (foreachExample.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV0WLI59XXHA",
        "outputId": "3b174991-9155-45b6-b99d-f22d8eb5714e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [1, 2, 3]\n",
            "None\n",
            "1\n",
            "2\n",
            "3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF"
      ],
      "metadata": {
        "id": "jy_8BUWElKni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "documents = [\"apple orange apple\", \"apple lemon\", \"orange lemon\"]\n",
        "rdd = sc.parallelize(documents)\n",
        "\n",
        "# TF calculation\n",
        "tf_rdd = rdd.map(lambda doc: Counter(doc.split()))\n",
        "\n",
        "# IDF calculation\n",
        "idf_rdd = tf_rdd.flatMap(lambda tf: tf.keys()).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "N = rdd.count()\n",
        "idf_values = idf_rdd.mapValues(lambda count: math.log(N / count)).collectAsMap()\n",
        "\n",
        "# TF-IDF calculation\n",
        "tfidf_rdd = tf_rdd.map(lambda tf: {word: tf[word] * idf_values[word] for word in tf})\n",
        "\n",
        "tfidf = tfidf_rdd.collect()\n",
        "print(tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWeHysOPXltk",
        "outputId": "f1b8c8ee-3835-4d05-a26d-c9f96217eb04"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'apple': 0.8109302162163288, 'orange': 0.4054651081081644}, {'apple': 0.4054651081081644, 'lemon': 0.4054651081081644}, {'orange': 0.4054651081081644, 'lemon': 0.4054651081081644}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fullOuterJoin\n",
        "\n",
        "\n",
        "rdd1 = sc.parallelize( [(1, 'a'), (1, 'b'), (5, 'c'), (2, 'd'), (3, 'e')])\n",
        "rdd2 = sc.parallelize([(1, 'AA'), (5, 'BB'), (5, 'CC'), (6, 'DD')])\n",
        "\n",
        "\n",
        "rdd1.fullOuterJoin(rdd2).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8efnUr72lQSf",
        "outputId": "6bd092fc-ce14-443c-9772-bffab7055204"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, ('d', None)),\n",
              " (6, (None, 'DD')),\n",
              " (1, ('a', 'AA')),\n",
              " (1, ('b', 'AA')),\n",
              " (5, ('c', 'BB')),\n",
              " (5, ('c', 'CC')),\n",
              " (3, ('e', None))]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating data frame"
      ],
      "metadata": {
        "id": "wE-tP_ru5M9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [('Chris', 'Berliner', 5)]\n",
        "spark.createDataFrame(a, ['drinker', 'beer', 'score']).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6AozDuI4FJB",
        "outputId": "a10fbaf8-fd57-470e-f489-e772b5c585d7"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(drinker='Chris', beer='Berliner', score=5)]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "likes = [('Chris', 'Bud'), ('Kia', 'Berliner'), ('Matt', 'ARJK')]\n",
        "frequents = [('Chris', 'Bohene'), ('Kia', 'Little'), ('Oscar', 'Griff')]\n",
        "\n",
        "likesName=['Drinker', 'Beer']\n",
        "frequentsName=['Drinker', 'Bar']\n",
        "\n",
        "likesDF = spark.createDataFrame(likes, likesName) # data as tuples and then column names as str\n",
        "frequentsDF = spark.createDataFrame(frequents, frequentsName)\n",
        "\n",
        "likesDF.show()\n",
        "frequentsDF.show()"
      ],
      "metadata": {
        "id": "1IBrOyzoN1DG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3d1206-8ef8-4b95-ba10-89036e46c9cb"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+\n",
            "|Drinker|    Beer|\n",
            "+-------+--------+\n",
            "|  Chris|     Bud|\n",
            "|    Kia|Berliner|\n",
            "|   Matt|    ARJK|\n",
            "+-------+--------+\n",
            "\n",
            "+-------+------+\n",
            "|Drinker|   Bar|\n",
            "+-------+------+\n",
            "|  Chris|Bohene|\n",
            "|    Kia|Little|\n",
            "|  Oscar| Griff|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# join"
      ],
      "metadata": {
        "id": "R5-Rlr1kLVft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "likesDF.join(frequentsDF, likesDF.Drinker == frequentsDF.Drinker, 'right').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7wPi9DlHXHh",
        "outputId": "1a1fba3a-6ea3-470f-8fb7-bb7b468c1296"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+------+\n",
            "|Drinker|    Beer|Drinker|   Bar|\n",
            "+-------+--------+-------+------+\n",
            "|  Chris|     Bud|  Chris|Bohene|\n",
            "|    Kia|Berliner|    Kia|Little|\n",
            "|   NULL|    NULL|  Oscar| Griff|\n",
            "+-------+--------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# full join"
      ],
      "metadata": {
        "id": "NlD6dQNaMKeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "likesDF.join(frequentsDF, likesDF.Drinker == frequentsDF.Drinker, 'full').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPRJNsb3MAtW",
        "outputId": "bfbde3b8-7480-420a-f6e8-aa9ac05ac93b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+------+\n",
            "|Drinker|    Beer|Drinker|   Bar|\n",
            "+-------+--------+-------+------+\n",
            "|  Chris|     Bud|  Chris|Bohene|\n",
            "|    Kia|Berliner|    Kia|Little|\n",
            "|   Matt|    ARJK|   NULL|  NULL|\n",
            "|   NULL|    NULL|  Oscar| Griff|\n",
            "+-------+--------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([('a', 1), ('b', 1), ('b', 1), ('a', 2)], ('id', 'c'))\n",
        "df.show()\n",
        "df.distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItDXBxDWMZx2",
        "outputId": "9f4539e8-6559-45da-8b40-f730078bde4b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+\n",
            "| id|  c|\n",
            "+---+---+\n",
            "|  a|  1|\n",
            "|  b|  1|\n",
            "|  b|  1|\n",
            "|  a|  2|\n",
            "+---+---+\n",
            "\n",
            "+---+---+\n",
            "| id|  c|\n",
            "+---+---+\n",
            "|  a|  1|\n",
            "|  b|  1|\n",
            "|  a|  2|\n",
            "+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([('a', 1), ('b', 1), ('b', 1), ('a', 2)], ('id', 'c'))\n",
        "df.show()\n",
        "rdd = df.rdd\n",
        "print(rdd.collect())\n",
        "\n",
        "print(df.rdd.map(list).collect())\n",
        "print(df.rdd.map(tuple).collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ep-CDWMsHl",
        "outputId": "3d7ee44c-7975-430c-bb22-8f2f3230c69d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+\n",
            "| id|  c|\n",
            "+---+---+\n",
            "|  a|  1|\n",
            "|  b|  1|\n",
            "|  b|  1|\n",
            "|  a|  2|\n",
            "+---+---+\n",
            "\n",
            "[Row(id='a', c=1), Row(id='b', c=1), Row(id='b', c=1), Row(id='a', c=2)]\n",
            "[['a', 1], ['b', 1], ['b', 1], ['a', 2]]\n",
            "[('a', 1), ('b', 1), ('b', 1), ('a', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# withColumn"
      ],
      "metadata": {
        "id": "JHZQJyPjNvWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([['a'], ['b'], ['b'], ['c']], (['word']))\n",
        "df.show()\n",
        "\n",
        "from pyspark.sql.functions import lit\n",
        "new_df=df.withColumn(\"COUNT\", lit(1))\n",
        "\n",
        "new_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhflq-DHM-3U",
        "outputId": "fa1cfdbd-0fe1-4a83-c625-dd72c2900021"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|word|\n",
            "+----+\n",
            "|   a|\n",
            "|   b|\n",
            "|   b|\n",
            "|   c|\n",
            "+----+\n",
            "\n",
            "+----+-----+\n",
            "|word|COUNT|\n",
            "+----+-----+\n",
            "|   a|    1|\n",
            "|   b|    1|\n",
            "|   b|    1|\n",
            "|   c|    1|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# groupby"
      ],
      "metadata": {
        "id": "yrVhpB8zN4XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as func\n",
        "new_df.groupBy(\"word\").agg(func.sum(\"COUNT\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w8oK25NN0Io",
        "outputId": "5d63ba1a-fdea-4e2c-aa1c-a26d11d1dc42"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+\n",
            "|word|sum(COUNT)|\n",
            "+----+----------+\n",
            "|   c|         1|\n",
            "|   b|         2|\n",
            "|   a|         1|\n",
            "+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "l = [('Alice', 25), ('Robert', 12), ('Chris', 45)]\n",
        "df = spark.createDataFrame(l, ['Name', 'Age'])\n",
        "df.show()\n",
        "\n",
        "\n",
        "maturity_udf = udf(lambda age: \"Adult\" if age >=18 else \"Child\", StringType())\n",
        "\n",
        "newdf=df.withColumn(\"Maturity\", maturity_udf(df.Age))\n",
        "newdf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5_gqlzYN-QQ",
        "outputId": "95949477-c05d-402e-be49-c6d25e04f12b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|  Name|Age|\n",
            "+------+---+\n",
            "| Alice| 25|\n",
            "|Robert| 12|\n",
            "| Chris| 45|\n",
            "+------+---+\n",
            "\n",
            "+------+---+--------+\n",
            "|  Name|Age|Maturity|\n",
            "+------+---+--------+\n",
            "| Alice| 25|   Adult|\n",
            "|Robert| 12|   Child|\n",
            "| Chris| 45|   Adult|\n",
            "+------+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.orderBy(\"Age\", ascending=False).limit(1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KKTWzPkOVOY",
        "outputId": "5e78098f-e2ff-4324-d35a-76df4cc71322"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Chris| 45|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "mat = np.random.rand(8,1).reshape(4, -1)\n",
        "\n",
        "rdd = sc.parallelize(mat)\n",
        "\n",
        "\n",
        "print(rdd.collect())\n",
        "\n",
        "rdd.reduce(lambda x, y: np.add(x, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABP_iKTUO-mh",
        "outputId": "7509f6d6-45f4-4542-e490-d5bfa2ed2628"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([0.11251234, 0.17830219]), array([0.22316913, 0.13379661]), array([0.34088103, 0.11210952]), array([0.76057994, 0.95400933])]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.43714244, 1.37821765])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectors"
      ],
      "metadata": {
        "id": "hkZ3gcAiPeFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "size=2\n",
        "\n",
        "data = [(0, Vectors.dense(np.random.rand(size)),),\n",
        "        (1, Vectors.dense(np.random.rand(size)),),\n",
        "        (1, Vectors.dense(np.random.rand(size)),),\n",
        "        (0, Vectors.dense(np.random.rand(size)),)]\n",
        "\n",
        "df = spark.createDataFrame(data, [\"label\", \"features\"])\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-SwBKXDPFkn",
        "outputId": "ebbd5dff-05f7-4fb5-822a-ceb96ad87565"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    0|[0.46434185773091...|\n",
            "|    1|[0.38309348198800...|\n",
            "|    1|[0.14640490330863...|\n",
            "|    0|[0.25840251307330...|\n",
            "+-----+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = Vectors.dense(np.round(np.random.rand(size), 2))\n",
        "b = Vectors.dense(np.round(np.random.rand(size), 2))\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "\n",
        "np.add(a , b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi93jwQMPp_z",
        "outputId": "690efc43-4663-460c-fc05-5475b08dd19a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.32,0.32]\n",
            "[0.41,0.55]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73, 0.87])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Partitioning\n",
        "\n"
      ],
      "metadata": {
        "id": "5wKbW4vOUzO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8]).map(lambda x: (x, x))\n",
        "\n",
        "pairs.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLp2c5K2Pwdm",
        "outputId": "5c3ebba2-4247-4e03-d12c-3a743302f6ad"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8)]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs.partitionBy(4).glom().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1-1w9yPU5GR",
        "outputId": "57ecf0e5-a082-427d-f479-500fcb12892f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(4, 4), (8, 8)], [(1, 1), (5, 5)], [(2, 2), (6, 6)], [(3, 3), (7, 7)]]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the coutn of data elements\n",
        "counts = pairs.count()\n",
        "print(counts)\n",
        "\n",
        "\n",
        "# First partition data based on number of batches.\n",
        "numberOfBatches = 4\n",
        "partitionedRDD = pairs.partitionBy(int(counts/numberOfBatches)).glom()\n",
        "\n",
        "\n",
        "# Then we can Loop through the model and train it.\n",
        "for i in range(4):\n",
        "\n",
        "    sets = partitionedRDD.map(lambda x: x[i]).collect()\n",
        "    print(\"Batch number  \", i, sets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5loD9TU7Mn",
        "outputId": "06361d87-a270-4dd7-d909-a203d29194ce"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "Batch number   0 [(2, 2), (1, 1)]\n",
            "Batch number   1 [(4, 4), (3, 3)]\n",
            "Batch number   2 [(6, 6), (5, 5)]\n",
            "Batch number   3 [(8, 8), (7, 7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# treeAggregate()"
      ],
      "metadata": {
        "id": "gcRKDu_0Yj7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([2, 2, 2, 2, 2, 2, 2, 2], 8)\n",
        "# Create a threeAggregate that calculate the sum of the elements and counts the elements\n",
        "a =  rdd.treeAggregate((0,0), lambda x, y: (x[0]+y, x[1]+1) , lambda x, y: (x[0]+y[0],x[1]+y[1]))\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa6NbMGgVjD7",
        "outputId": "29f8dbb5-7bc4-40a9-c261-01d308d7c41e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a =  rdd.repartition(1)\\\n",
        "    .treeAggregate((1, 1), lambda x, y: (x[0]+y, x[1]+1) , lambda x, y: (x[0]+y[0],x[1]+y[1]))\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lokuWN3aZG4-",
        "outputId": "3f885189-b497-47a3-b8fc-6e4dac035c67"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# aggregateByKey"
      ],
      "metadata": {
        "id": "s5RnxbGq7Ti9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = sc.parallelize([(\"A\",3),(\"A\",4),(\"A\",5),(\"A\",6),(\"B\",8),(\"B\",9),], 3)\n",
        "print(\"partitions\\n\",ratings.glom().collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4q_lrFlapF5",
        "outputId": "e50e29e8-7ed5-4e04-ad84-81d6e5ff9291"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "partitions\n",
            " [[('A', 3), ('A', 4)], [('A', 5), ('A', 6)], [('B', 8), ('B', 9)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_count = ratings.aggregateByKey((0,0),\n",
        "                                   (lambda C,V: (C[0]+V, C[1]+1)),\n",
        "                                   (lambda C1, C2: (C1[0]+C2[0],C1[1]+C2[1])))\n",
        "\n",
        "print(sum_count.collect())\n",
        "# here we have initialized (0,0) and then used the first lambda fn to do itra partittion\n",
        "# calculations and then in the later lambda fn we do inter partition sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcgW83KP7X_l",
        "outputId": "2eee4c76-7f6c-4fe9-90cd-04a5e97f1205"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('B', (17, 2)), ('A', (18, 4))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4-PVosCF8Ekc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}